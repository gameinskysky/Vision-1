\chapter{Results and Discussion}
\label{sec:results}

We want to discuss three different evaluations. Section \ref{sec:ijrr} shows a comparison between ROVIO and OKVIS on a long dataset collected indoors, which will demonstrate performance of the two algorithms and make visible drifting issues. Section \ref{sec:euroc} will show ROVIO results on a second complementary dataset with slower dynamics and will reveal that accuracy differs for different datasets. Finally, the third section \ref{sec:timesync} will approach the question if ROVIO is able to run with a generic sensor system.

\section{Comparison of ROVIO and OKVIS on long indoor dataset}
\label{sec:ijrr}

The comparison of ROVIO and OKVIS will be done on a dataset, which was collected with the visual-inertial sensor unit shown in figure \ref{pics:visensor} a (Nikolic et al., \cite{nikolic2014synchronized}). This VI-sensor is equipped with two global-shutter cameras with a field of view of 120 degrees, which are hardware-wise time-synchronized to an industrial-grade ADIS 16448 IMU. The presented results are all based on the data of the IMU and a single camera.

\begin{figure}
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{images/visensor.png}
    \caption{}
    \label{fig:1}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{images/ijrr/2D_rovio.png}
    \caption{}
    \label{fig:2}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{images/ijrr/2D_okvis.png}
    \caption{}
    \label{fig:2}
  \end{subfigure}
   \caption{The visual-inertial sensor unit (a), equipped with two cameras and an IMU, which are hardware-wise time synchronized. (b) and (c) give a visual impression about the tracking performance of ROVIO and OKVIS, respectively.}
   \label{pics:visensor}
\end{figure}

The dataset has been collected some time ago by Leutenegger et al., \cite{leutenegger2015keyframe}, to demonstrate the OKVIS performance. The published results on OKVIS will be compared with new results of ROVIO running on the same dataset. The data contains a trajectory with a travelled distance of $1200 m$ collected indoors by performing approximately 100 loops within a vicon room. The camera was facing in direction of movement for the whole dataset. The camera was moved hand-held and the dynamics are rather fast with $2 \frac{m}{s}$ and $3 \frac{rad}{s}$.

Figures \ref{pics:visensor} b and c show the ground truth and estimated trajectories in 2D and give a visual impression on the tracking performance of the two algorithms. It is not clear out of the graphs, but what happened was that the tracking of the "circle" was quite accurate in the beginning for both algorithms and drifted over time.

\subsection{Global accuracy}
\label{sec:ijrr_global}

Figure \ref{pics:ijrr_abs} shows the absolute translation and orientation errors of ROVIO and OKVIS for this dataset in direct comparison with median value and 25 and 75 percentiles. After a travelled distance of $1000 m$ ROVIO shows a translation error of $2.5 m$ ($0.25\%$), which is three times higher than the one of OKVIS with less than $1 m$ ($<0.1\%$). The absolute orientation error after a travelled distance of $1000 m$ of ROVIO is around $45$ degrees, which is ten times higher than for OKVIS ($4$ degrees). 

\begin{figure}[h]
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{images/ijrr/ate.png}
    \caption{}
    \label{fig:2}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{images/ijrr/aoe.png}
    \caption{}
    \label{fig:2}
  \end{subfigure}
   \caption{The absolute translation (a) and orientation (b) errors for the two algorithms in direct comparison. After a travelled distance of 1000 $m$ the absolute translation error of ROVIO is 3 times higher than the one of OKVIS, the absolute orientation error is 10 times higher.}
   \label{pics:ijrr_abs}
\end{figure}

To better understand what is happening over time it makes sense to look at the 6 degrees of freedom separately. Figure \ref{pics:ijrr_abs_separate} shows the errors for roll, pitch, yaw, x, y and z separately.


The roll and pitch errors (figure \ref{pics:ijrr_abs_separate} a and b) are bounded and below $1$ degree for both algorithms over the whole sequence and 2-3 times higher for ROVIO than for OKVIS. The yaw error (figure \ref{pics:ijrr_abs_separate} c) is drifting over time and contains the main contribution to the absolute orientation error. Thanks to the IMU measurements the gravity vector is observable and therefore visual-inertial localization algorithms are only prone to drift around the world-z axis, which is the yaw-axis. The world-x and world-y errors (figure \ref{pics:ijrr_abs_separate} d and e) are mainly driven by the yaw-error and strongly dependent on the dataset itself. For a trajectory including $1000 m$ collected in a straight line, a yaw-error of 45 degrees would sum up to huge world-x and world-y errors. The world-z error (figure \ref{pics:ijrr_abs_separate} f) gives again new insights into the drift issues within an algorithm. ROVIO shows with $1m$ after $1000m$ a world-z error, which is 3 times higher than the one of OKVIS. \\

\begin{figure}[h]
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{images/ijrr/aoe_r.png}
    \caption{}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{images/ijrr/aoe_p.png}
    \caption{}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{images/ijrr/aoe_y.png}
    \caption{}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{images/ijrr/ate_x.png}
    \caption{}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{images/ijrr/ate_y.png}
    \caption{}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{images/ijrr/ate_z_2.png}
    \caption{}
  \end{subfigure}
   \caption{The absolute errors for the separated axes. Roll (a) and pitch (b) stay bounded and below $1$ degree for both algorithms over the whole sequence. Yaw (c) is drifting over time and has the main contribution to the absolute orientation error. The world-x (d) and world-y (e) errors are mainly driven by yaw and strongly dependent on the data and the world-z error (f) of OKVIS after $1000 m$ is three times lower than the one of ROVIO.}
   \label{pics:ijrr_abs_separate}
\end{figure}

Main results out of this comparison include that
\begin{itemize}
\item OKVIS shows superior performance regarding global accuracy than ROVIO and
\item ROVIO is prone to drift, especially in yaw, with a yaw-error of 45 degrees after $1000m$.
\end{itemize}

The main reasons for the superior performance of OKVIS are linearization errors within ROVIO and the filtering-based property of not correcting a past estimate based on a new observation (see section \ref{sec:rovio}). 
A future way of approaching the drifting issue could be to perform a global optimization in a secondary module, which takes the output of the algorithm and performs a computationally more expensive optimization on a slower rate and feeds its result back. This secondary module could also detect loop closures and increase the global accuracy significantly. Another easier way of reducing the drift issue would be to include additional sensor information of a magnetometer or even GPS into the estimation. Using only a magnetometer could decrease the yaw-drift already significantly.


\subsection{Local accuracy}
\label{sec:ijrr_local}

Over short distances the difference between the two algorithms is very small. Figure \ref{pics:ijrr_rel} shows the relative translation and orientation errors for the long indoor trajectory. The relative translation error of ROVIO is a bit higher than the one of OKVIS but in the same order of magnitude: After a travelled distance of $1 m$ both algorithms have a median relative translation error of approximately $2cm$ ($2\%$). The relative orientation error is very similar and approximately $0.6$ degrees after a travelled distance of $1m$.

\begin{figure}[h]
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{images/ijrr/rte.png}
    \caption{}
    \label{fig:2}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{images/ijrr/roe.png}
    \caption{}
    \label{fig:2}
  \end{subfigure}
   \caption{The relative translation (a) and orientation (b) errors for the two algorithms in direct comparison. After a travelled distance of $1 m$ the relative translation error of ROVIO is a bit higher than the one of OKVIS, but in the same order of magnitude, the absolute orientation error is similar for both algorithms.}
   \label{pics:ijrr_rel}
\end{figure}

A local accuracy in this order of magnitude is probably the best one can get out of a visual-inertial localization algorithm at the moment. The presented results on local accuracy are hard to compare with the literature because such in depth analyses of local errors have never been published on other promising visual-inertial localization implementations. The accuracies are probably in a order of magnitude, which allow subsequent algorithms like dense reconstruction or object recognition to work reasonably. For direct manipulation tasks the accuracies are probably too bad and a subsequent estimation technique for relative pose estimation between the robot and a target needs to be added.


\subsection{Computational complexity}
\label{sec:ijrr_complexity}

As mentioned in sections \ref{sec:rovio} and \ref{sec:okvis} ROVIO and OKVIS differ in their estimation techniques and OKVIS is working with more information than ROVIO. Parts of the algorithms like the data acquisition or feature extraction are in the same order of computational complexity for the two algorithms but the estimation itself of OKVIS is clearly more demanding. We have not been able to run OKVIS on the same machine as ROVIO and therefore a direct comparison of computational complexity can not been demonstrated within this report. Working with a maximum number of 25 features the processing time per frame of ROVIO on a 2.5GHz Intel Core macbook was $10ms$ per frame, which is rather lightweight. We know of OKVIS that is computationally more demanding but still able to run in real-time on a standard laptop processor.


\section{Evaluation of ROVIO on complementary indoor dataset}
\label{sec:euroc}

The presented results have been derived on one specific dataset. To get a better impression for the presented numbers this section will show ROVIO results on a second dataset with other characteristics. It has also been collected with the VI-sensor (figure \ref{pics:visensor} a) and contains a short indoor trajectory with a travelled distance of $60m$. The dynamics on this dataset are slower with $1\frac{m}{s}$ and less than $1\frac{rad}{s}$. The camera was moved in direction of all body axes, not only in direction of the optical axis and the data looks like a slowly performed random walk, see figure \ref{pics:euroc} a. \\

\begin{figure}[h]
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{images/euroc/2D.png}
    \caption{}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{images/euroc/ate.png}
    \caption{}
  \end{subfigure}
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{images/euroc/aoe.png}
    \caption{}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{images/euroc/aoe_y.png}
    \caption{}
  \end{subfigure}
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{images/euroc/rte.png}
    \caption{}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{images/euroc/roe.png}
    \caption{}
  \end{subfigure}
   \caption{ROVIO performance on second dataset: The absolute translation error (b) lies between $10cm$ and $20cm$ after $50m$ of travelled distance and the absolute orientation error (c) after $50m$ is around $1$ degree. The major contribution to the absolute orientation error is coming from the absolute yaw error (d). The local translation error (e) with $3-4cm$ after $1m$ is higher for this dataset than for the long trajectory and the local orientation error (f) with $0.6$ degrees after $1m$ is similar to the long trajectory.}
   \label{pics:euroc}
\end{figure}

Looking at the global accuracy (figure \ref{pics:euroc} b, c and d) with an absolute translation error of $10-20cm$ and $1$ degree after a travelled distance of $50m$, we notice that the observed drifting issues in section \ref{sec:ijrr} are not obviously visible over these short distances. Especially in yaw we can not register clear drift on this short sequence. \\

Regarding local accuracy (figure \ref{pics:euroc} e and f) we notice a clearly higher relative translation error with $3-4cm$ compared with $2cm$ for the long trajectory after $1m$ of travelled distance. The relative orientation error of $0.6$ degrees is similar to the one of the long trajectory. The reason why local accuracy is better on the long trajectory lies probably in the higher dynamics within that set. The IMU measurements are less noisy for higher excitements and two frames with a travelled distance of $1m$ in between have been captured nearer in time. \\

For a task like dense reconstruction or maintenance this second dataset is probably more representative as a robot won't move with high speeds during this kind of operation. Therefore relative errors of $3-4cm$ and $0.6$ degrees have to be expected for a travelled distance of $1m$.

\section{Towards a non time synchronized sensor system}
\label{sec:timesync}

All the presented results have been derived on data collected with the VI-sensor (figure \ref{pics:visensor} a). The VI-sensor is hardware-wise time synchronized, which means that the camera image capture is triggered by the IMU. Thanks to this time synchronization the data of both sensors arrives on the visual-inertial localization algorithm accurately time-aligned. For many applications it will be an important question if a visual-inertial localization algorithm is also able to run with a more generic sensor system that does not perform a hardware time synchronization. \\

Within the scope of this report we will present two evaluations towards the question if ROVIO is able to run with a sensor system, which is not hardware-wise time synchronized. In section \ref{sec:timesync_artificial} data of the VI-sensor is passed to ROVIO, artificially modified with an added bias on the IMU timestamp. Section \ref{sec:timesync_real} will show experimental results by comparing ROVIO once running on a hardware-wise time synchronized and once on a hardware-wise non time synchronized sensor system.


\subsection{Artificial bias on IMU timestamp}
\label{sec:timesync_artificial}

By adding an artificial bias to the IMU timestamp, ROVIO has to deal with an inaccuracy, which is not modelled in the filter assumptions. Like that performance decreases and the filter eventually diverges when the bias gets too large. To get an impression how robustly the system behaves under errors in the timestamps we took the hardware-wise time synchronized VI-sensor data and added an artificial bias on the IMU timestamp to observe ROVIO's performance. \\

\begin{figure}[h]
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{images/artificial_bias_1.png}
    \caption{}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
    \includegraphics[width=\textwidth]{images/artificial_bias_2.png}
    \caption{}
  \end{subfigure}
   \caption{Evaluation of ROVIO performance on data from the VI-sensor artificially modified by adding a bias between $0ms$ and $100ms$ on the IMU timestamp. The evaluation is based on the second dataset (section \ref{sec:euroc}) and demonstrates that ROVIO is able to handle biases on below $50ms$ and diverges for $100ms$ on this data with slow dynamics. Fixing the camera-IMU extrinsics, ROVIO is even more robust when faced with large biases.}
   \label{pics:timesync_artificial}
\end{figure}

Figure \ref{pics:timesync_artificial} shows the mean absolute translation and orientation errors of ROVIO for artificial timestamp biases between $0ms$ (original mode) and $100ms$ in steps of $10ms$. The evaluation is performed on the second dataset, introduced in section \ref{sec:euroc}. The first observation is that, for this slow dynamic dataset, ROVIO is only diverging with an artificial timestamp bias of $100ms$ and stays quite accurate untill $50ms$. The second observation is that it is manly the online estimation of the translational and rotational extrinsics between camera and IMU, which cause the filter to diverge. By fixing these extrinsics and reducing some degrees of freedom within the filter state, ROVIO is even more robust regarding a bias on the IMU timestamp. Fixing the camera-IMU extrinsics can only help if an accurate calibration is available and the extrinsics stay constant during operation since errors within the extrinsics will directly effect the accuracy.



\subsection{ROVIO results with and without time synchronization}
\label{sec:timesync_real}

To test and compare ROVIO on two sensor systems with and without time synchronization the sensor setup shown in figure \ref{pics:vi_bluefox} has been designed. It consists out of the VI-sensor and an added bluefox 2.0 camera, which has the same characteristics and the same field of view as the camera on the VI-sensor. With this setup we are able to compare ROVIO running with the hardware-wise time synchronized data of the VI-sensor with ROVIO running on the hardware-wise non time synchronized data of the bluefox camera and the VI-sensor-IMU. We collected two datasets with different dynamics and vicon ground truth, the first contains slow motions ($1.5\frac{m}{s}$ and $1\frac{rad}{s}$) the second contains fast and shaky dynamics ($2.5\frac{m}{s}$ and $5\frac{rad}{s}$). For both datasets the camera was moved hand-held, the camera was facing in direction of movement and a distance of $60m$ was collected, which was three loops within the vicon room. \\

\begin{figure}[h]
   \centering
   \includegraphics[width=0.4\textwidth]{images/vi_bluefox.JPG}
   \caption{The experimental sensor setup consisted out of the VI-sensor and an added bluefox 2.0 camera (left). The bluefox camera has the same characteristics and field of view as the camera of the VI-sensor.}
   \label{pics:vi_bluefox}
\end{figure}

For the dataset with slow dynamics (figure \ref{pics:timesync_slow}) ROVIO is principally able to track the motion of the sensor system for both the hardware-wise time synchronized (VI-sensor) and the non time synchronized (bluefox and VI-sensor-IMU) data. Not too surprisingly the tracking performance of ROVIO running on the VI-sensor data is more accurate (see also appendix \ref{pics:appendix_slow}) but the important result is that there seems not to be a larger issue with the missing hardware time synchronization for ROVIO if the robot is moving with slow motions. \\

\begin{figure}
  \begin{subfigure}[b]{0.46\textwidth}
    \includegraphics[width=\textwidth]{images/slow.png}
    \caption{}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.42\textwidth}
    \includegraphics[width=\textwidth]{images/slow_2D.png}
    \caption{}
  \end{subfigure}
   \caption{Both datasets have been collected in a vicon room with lots of visible landmarks (a). ROVIO is principially able to track the motion of the sensor system with both the time synchronized (visensor) and the non time synchronized (bluefox and visensor-imu) data (b).}
   \label{pics:timesync_slow}
\end{figure}

For the dataset with fast motions the outcome is different (figure \ref{pics:timesync_fast} a). ROVIO running with the non time synchronized data is diverging on this set. At the same time ROVIO running with the time synchronized data is not diverging - comparing with the slow dataset the errors are significantly increasing (see also appendix \ref{pics:appendix_fast}), but tracking is not lost. If we fix the extrinsics between camera and IMU and hence reduce the number of degrees of freedom in the filter state, ROVIO can be prevented from divergence also on this fast set (figure \ref{pics:timesync_fast} b). \\

\begin{figure}
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{images/fast_2D.png}
    \caption{}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{images/fast_fixed_2D.png}
    \caption{}
  \end{subfigure}
   \caption{ROVIO is diverging with the non time synchronized data for the dataset with fast and shaky motions (a) while still able to track with the time synchronized data. Fixing the camera-IMU extrinsics (b) prevents the algorithm from divergence for this dataset.}
   \label{pics:timesync_fast}
\end{figure}

Summarizing the most important results on the analysis towards a non time synchronized sensor setup, we found that

\begin{itemize}
\item ROVIO is principially able to run with a hardware-wise non time synchronized sensor system,
\item the performance of ROVIO with hardware time synchronization is better,
\item hardware time synchronization gets important for high dynamics, and,
\item fixing the extrinsics between camera and IMU can increase the robustness of ROVIO regarding time synchronization.
\end{itemize}

As a future work, these results encourage to go a step further and run ROVIO on an embedded system with a hardware-wise non time synchronized sensor system.













